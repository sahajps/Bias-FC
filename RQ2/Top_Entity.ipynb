{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(s):\n",
    "    \"\"\"\n",
    "    Ofcourse GPT-3.5 is a smart model and capable enough to return the results in said format (in-most of the cases).\n",
    "    This function is trying to extract then entity-sentiment pair in a dict format.\n",
    "    \"\"\"\n",
    "    s = s[1:-1]\n",
    "    dic = {}\n",
    "\n",
    "    positions=[match.end() for match in re.finditer(r'\\b(?:positive|negative|neutral)\\b,', s, flags=re.IGNORECASE)]\n",
    "    for ss in [s[i:j] for i, j in zip([0] + positions, positions + [None])]:\n",
    "        tmp = ss.split(':')\n",
    "        try:\n",
    "            dic[tmp[0]] = tmp[1].replace(\",\", \"\")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return dic\n",
    "\n",
    "def prepros(df):\n",
    "    \"\"\"\n",
    "    Some basic preprocessing & mapping of string sentiment data to dict format\n",
    "    \"\"\"\n",
    "    df.sentiments = df.sentiments.str.replace('[\\n\"\\']', '', regex=True)\n",
    "    df.sentiments = df.sentiments.str.replace(r'{\\s+', '{', regex=True)\n",
    "    df.sentiments = df.sentiments.str.replace(r'\\s+}', '}', regex=True)\n",
    "    df.sentiments = df.sentiments.str.replace(r':\\s+', ':', regex=True)\n",
    "    df.sentiments = df.sentiments.str.replace(r',\\s+', ',', regex=True)\n",
    "    df.sentiments = df.sentiments.apply(conv)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['checkyourfact.xlsx', 'politifact.xlsx', 'snopes.xlsx', 'altnews.xlsx', 'boomlive.xlsx', 'opindia.xlsx']\n",
    "\n",
    "for f in files:\n",
    "    \"\"\"\n",
    "    After processing the data, it's saving top 100 most frequent entities to be annotated.\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(\"Entity Sentiment Data/\"+f)\n",
    "    df = prepros(df)\n",
    "\n",
    "    entities = []\n",
    "\n",
    "    for dic in df.sentiments:\n",
    "        entities += list(dic)\n",
    "\n",
    "    top100 = pd.Series(entities).value_counts()[:100]\n",
    "\n",
    "    tmp = pd.DataFrame()\n",
    "    tmp['ent'] = top100.index\n",
    "    tmp['count'] = top100.values\n",
    "\n",
    "    # After saving the below file, manual annotation is done to include only top poltical entities ant their uniform mapping\n",
    "    # for ex: pm modi, pm narendra modi and narendra modi will map to narendra modi !!\n",
    "    # tmp.to_excel('Top Entity/'+f, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
