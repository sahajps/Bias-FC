{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "704fb82d-8375-46df-88c8-4f587da3629e",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe349dcf",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def conv(s):\n",
    "    \"\"\"\n",
    "    Ofcourse GPT-3.5 is a smart model and capable enough to return the results in said format (in-most of the cases).\n",
    "    This function is trying to extract then entity-sentiment pair in a dict format.\n",
    "    \"\"\"\n",
    "    s = s[1:-1]\n",
    "    dic = {}\n",
    "\n",
    "    positions=[match.end() for match in re.finditer(r'\\b(?:positive|negative|neutral)\\b,', s, flags=re.IGNORECASE)]\n",
    "    for ss in [s[i:j] for i, j in zip([0] + positions, positions + [None])]:\n",
    "        tmp = ss.split(':')\n",
    "        try:\n",
    "            dic[tmp[0]] = tmp[1].replace(\",\", \"\")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return dic\n",
    "\n",
    "def prepros(df):\n",
    "    \"\"\"\n",
    "    Some basic preprocessing & mapping of string sentiment data to dict format\n",
    "    \"\"\"\n",
    "    df.sentiments = df.sentiments.str.replace('[\\n\"\\']', '', regex=True)\n",
    "    df.sentiments = df.sentiments.str.replace(r'{\\s+', '{', regex=True)\n",
    "    df.sentiments = df.sentiments.str.replace(r'\\s+}', '}', regex=True)\n",
    "    df.sentiments = df.sentiments.str.replace(r':\\s+', ':', regex=True)\n",
    "    df.sentiments = df.sentiments.str.replace(r',\\s+', ',', regex=True)\n",
    "    df.sentiments = df.sentiments.apply(conv)\n",
    "\n",
    "    return df\n",
    "\n",
    "def map_to_root(df, mapping):\n",
    "    \"\"\"\n",
    "    Returns a dict with poltical entities as keys and list of sentiments in values\n",
    "    1. Entity names is used as per the annotated mapping (Top Entity folder)\n",
    "    2. If entity isn't in top entity list then we are not including them into this dict.\n",
    "       (B/C after top-100 frequency drops significantly)\n",
    "    \"\"\"\n",
    "    top = list(mapping.index)\n",
    "    top_dic = {}\n",
    "    for dic in df.sentiments:\n",
    "        for k in dic:\n",
    "            if k in top:\n",
    "                try:\n",
    "                    top_dic[mapping.loc[k].loc['map']] += [dic[k]]\n",
    "                except:\n",
    "                    top_dic[mapping.loc[k].loc['map']] = [dic[k]]\n",
    "\n",
    "    return top_dic\n",
    "\n",
    "def sent_count(l):\n",
    "    \"\"\"\n",
    "    Given a list of sentiments eg:['positive', 'positive', 'negative', 'neutral', 'positive']]\n",
    "    Return dict with sentiment count\n",
    "    \"\"\"\n",
    "    dic = {'positive': 0, 'negative': 0, 'neutral': 0}\n",
    "    for i in l:\n",
    "        try:\n",
    "            dic[i] +=1\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return dic\n",
    "\n",
    "def polarity_score(d):\n",
    "    \"\"\"\n",
    "    Given a sentiment count dict, it returns the polarity score as defined in the paper\n",
    "    If it's an empty list then PS is 0.\n",
    "    \"\"\"\n",
    "    P = d['positive']\n",
    "    N = d['negative']\n",
    "    T = sum(d.values())\n",
    "\n",
    "    try:\n",
    "        return (P-N)/T\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5ecaa89",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def Main(f, y):\n",
    "    \"\"\"\n",
    "    Takes org name and year as input (y = \"all\" mean take full data !)\n",
    "    And returns the top sentiment entity dict in sorted order [on basis of frequency]\n",
    "    The keys of dict represent the political entities and the values are simple sentiment count dict\n",
    "    \"\"\"\n",
    "    mapping = pd.read_excel('Top Entity/'+f)\n",
    "    mapping = mapping[mapping.include==1]\n",
    "\n",
    "    mapping.index = list(mapping.ent)\n",
    "\n",
    "    df = pd.read_excel('Entity Sentiment Data/'+f)\n",
    "\n",
    "    if(y!='all'):\n",
    "        df = df[df.date_year==y]\n",
    "\n",
    "    df = prepros(df)\n",
    "\n",
    "    top_senti_list = map_to_root(df, mapping)\n",
    "\n",
    "    for k in top_senti_list:\n",
    "        top_senti_list[k] = sent_count(top_senti_list[k])\n",
    "\n",
    "    top_senti_list = dict(sorted(top_senti_list.items(), key=lambda x: x[1]['positive'] + x[1]['negative'] + x[1]['neutral'], reverse=True))\n",
    "\n",
    "    return top_senti_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1498121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkyourfact.xlsx \t -0.11610169491525424\n",
      "politifact.xlsx \t -0.10361752408652972\n",
      "snopes.xlsx \t -0.27574266447967927\n",
      "altnews.xlsx \t -0.2747336377473364\n",
      "boomlive.xlsx \t -0.18501805054151624\n",
      "opindia.xlsx \t -0.24912689173457508\n"
     ]
    }
   ],
   "source": [
    "files = ['checkyourfact.xlsx',\n",
    " 'politifact.xlsx',\n",
    " 'snopes.xlsx',\n",
    " 'altnews.xlsx',\n",
    " 'boomlive.xlsx',\n",
    " 'opindia.xlsx']\n",
    "\n",
    "for f in files:\n",
    "    \"\"\"\n",
    "    Looking over the orgs to first get the overall sentiment counts,\n",
    "    then printing the overall PS for each organization\n",
    "    \"\"\"\n",
    "    top_senti_all = Main(f, 'all')\n",
    "\n",
    "    alloverall = {'positive': 0, 'negative': 0, 'neutral': 0}\n",
    "\n",
    "    for i in top_senti_all:\n",
    "        tmp = top_senti_all[i]\n",
    "        for j in tmp:\n",
    "            try:\n",
    "                alloverall[j] += tmp[j]\n",
    "            except:\n",
    "                print(i,j)\n",
    "\n",
    "    print(f, \"\\t\", polarity_score(alloverall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
