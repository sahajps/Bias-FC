{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "from statistics import mean \n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(s):\n",
    "    s = s[1:-1]\n",
    "    dic = {}\n",
    "\n",
    "    positions=[match.end() for match in re.finditer(r'\\b(?:positive|negative|neutral)\\b,', s, flags=re.IGNORECASE)]\n",
    "    for ss in [s[i:j] for i, j in zip([0] + positions, positions + [None])]:\n",
    "        tmp = ss.split(':')\n",
    "        try:\n",
    "            dic[tmp[0]] = tmp[1].replace(\",\", \"\")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return dic\n",
    "\n",
    "def prepros(df, feature):\n",
    "    df[feature] = df[feature].str.replace('[\\n\"\\']', '', regex=True)\n",
    "    df[feature] = df[feature].str.replace(r'{\\s+', '{', regex=True)\n",
    "    df[feature] = df[feature].str.replace(r'\\s+}', '}', regex=True)\n",
    "    df[feature] = df[feature].str.replace(r':\\s+', ':', regex=True)\n",
    "    df[feature] = df[feature].str.replace(r',\\s+', ',', regex=True)\n",
    "    df[feature] = df[feature].apply(conv)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiments</th>\n",
       "      <th>claim_norm_list</th>\n",
       "      <th>who_what_list</th>\n",
       "      <th>HSent1</th>\n",
       "      <th>RelClaim1</th>\n",
       "      <th>RelWhat1</th>\n",
       "      <th>RelWhy1</th>\n",
       "      <th>HSent2</th>\n",
       "      <th>RelClaim2</th>\n",
       "      <th>RelWhat2</th>\n",
       "      <th>RelWhy2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bloggers stated on January 20, 2020 in a Faceb...</td>\n",
       "      <td>For some, the impeachment trial outcome is a f...</td>\n",
       "      <td>{'nancy pelosi': 'negative', 'donald trump': '...</td>\n",
       "      <td>[\"the headline claims u.s. house speaker nancy...</td>\n",
       "      <td>{'what': [\"the headline claims u.s. house spea...</td>\n",
       "      <td>{'nancy pelosi': 'neutral', 'donald trump': 'n...</td>\n",
       "      <td>[2,1,2]</td>\n",
       "      <td>[2,2,2]</td>\n",
       "      <td>[1,2]</td>\n",
       "      <td>{'nancy pelosi': 'neutral', 'donald trump': 'n...</td>\n",
       "      <td>[2,0,1]</td>\n",
       "      <td>[2,2,1]</td>\n",
       "      <td>[0,1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ted Cruz stated on December 15, 2020 in a twee...</td>\n",
       "      <td>U.S. Sen. Ted Cruz, R-Texas, took to Twitter T...</td>\n",
       "      <td>{'ted cruz': 'negative', 'donald trump': 'posi...</td>\n",
       "      <td>['the emerging vaccines each were placed throu...</td>\n",
       "      <td>{'what': [\"the guidance issued by the cdc that...</td>\n",
       "      <td>{'ted cruz': 'negative', 'donald trump': 'posi...</td>\n",
       "      <td>[2,2]</td>\n",
       "      <td>[2,2]</td>\n",
       "      <td>[2,2]</td>\n",
       "      <td>{'ted cruz': 'negative'}</td>\n",
       "      <td>[2,2]</td>\n",
       "      <td>[2,2]</td>\n",
       "      <td>[0,0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rebecca Dallet stated on March 2, 2018 in a de...</td>\n",
       "      <td>With the Florida school shooting still fresh o...</td>\n",
       "      <td>{'ron johnson': 'negative', 'tammy baldwin': '...</td>\n",
       "      <td>[\"dallet says that during the supreme court ca...</td>\n",
       "      <td>{'what': ['screnock did win the nra’s endorsem...</td>\n",
       "      <td>{'ron johnson': 'negative', 'tammy baldwin': '...</td>\n",
       "      <td>[2,2]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>{'ron johnson': 'negative', 'tammy baldwin': '...</td>\n",
       "      <td>[2,2]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Viral image stated on November 8, 2022 in an I...</td>\n",
       "      <td>Republican U.S. Senate candidate Dr. Mehmet Oz...</td>\n",
       "      <td>{'republicans': 'negative'}</td>\n",
       "      <td>['claims that a pennsylvania judge said ballot...</td>\n",
       "      <td>{'what': ['claims that a pennsylvania judge sa...</td>\n",
       "      <td>{'republicans': 'negative'}</td>\n",
       "      <td>[2,2,2]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[2,2]</td>\n",
       "      <td>{'republicans': 'negative'}</td>\n",
       "      <td>[2,0,2]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[2,2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Viral image stated on October 19, 2022 in an I...</td>\n",
       "      <td>Ukrainian President Volodymyr Zelenskyy is smi...</td>\n",
       "      <td>{'vladimir putin': 'negative'}</td>\n",
       "      <td>[\"since russia invaded ukraine, russian presid...</td>\n",
       "      <td>{'what': [\"the photo was altered to show ukrai...</td>\n",
       "      <td>{'vladimir putin': 'negative'}</td>\n",
       "      <td>[2,2]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>{'vladimir putin': 'negative'}</td>\n",
       "      <td>[2,2]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Bloggers stated on January 20, 2020 in a Faceb...   \n",
       "1  Ted Cruz stated on December 15, 2020 in a twee...   \n",
       "2  Rebecca Dallet stated on March 2, 2018 in a de...   \n",
       "3  Viral image stated on November 8, 2022 in an I...   \n",
       "4  Viral image stated on October 19, 2022 in an I...   \n",
       "\n",
       "                                                text  \\\n",
       "0  For some, the impeachment trial outcome is a f...   \n",
       "1  U.S. Sen. Ted Cruz, R-Texas, took to Twitter T...   \n",
       "2  With the Florida school shooting still fresh o...   \n",
       "3  Republican U.S. Senate candidate Dr. Mehmet Oz...   \n",
       "4  Ukrainian President Volodymyr Zelenskyy is smi...   \n",
       "\n",
       "                                          sentiments  \\\n",
       "0  {'nancy pelosi': 'negative', 'donald trump': '...   \n",
       "1  {'ted cruz': 'negative', 'donald trump': 'posi...   \n",
       "2  {'ron johnson': 'negative', 'tammy baldwin': '...   \n",
       "3                        {'republicans': 'negative'}   \n",
       "4                     {'vladimir putin': 'negative'}   \n",
       "\n",
       "                                     claim_norm_list  \\\n",
       "0  [\"the headline claims u.s. house speaker nancy...   \n",
       "1  ['the emerging vaccines each were placed throu...   \n",
       "2  [\"dallet says that during the supreme court ca...   \n",
       "3  ['claims that a pennsylvania judge said ballot...   \n",
       "4  [\"since russia invaded ukraine, russian presid...   \n",
       "\n",
       "                                       who_what_list  \\\n",
       "0  {'what': [\"the headline claims u.s. house spea...   \n",
       "1  {'what': [\"the guidance issued by the cdc that...   \n",
       "2  {'what': ['screnock did win the nra’s endorsem...   \n",
       "3  {'what': ['claims that a pennsylvania judge sa...   \n",
       "4  {'what': [\"the photo was altered to show ukrai...   \n",
       "\n",
       "                                              HSent1 RelClaim1 RelWhat1  \\\n",
       "0  {'nancy pelosi': 'neutral', 'donald trump': 'n...   [2,1,2]  [2,2,2]   \n",
       "1  {'ted cruz': 'negative', 'donald trump': 'posi...     [2,2]    [2,2]   \n",
       "2  {'ron johnson': 'negative', 'tammy baldwin': '...     [2,2]      [1]   \n",
       "3                        {'republicans': 'negative'}   [2,2,2]      [2]   \n",
       "4                     {'vladimir putin': 'negative'}     [2,2]      [1]   \n",
       "\n",
       "  RelWhy1                                             HSent2 RelClaim2  \\\n",
       "0   [1,2]  {'nancy pelosi': 'neutral', 'donald trump': 'n...   [2,0,1]   \n",
       "1   [2,2]                           {'ted cruz': 'negative'}     [2,2]   \n",
       "2     [2]  {'ron johnson': 'negative', 'tammy baldwin': '...     [2,2]   \n",
       "3   [2,2]                        {'republicans': 'negative'}   [2,0,2]   \n",
       "4     [1]                     {'vladimir putin': 'negative'}     [2,2]   \n",
       "\n",
       "  RelWhat2 RelWhy2  \n",
       "0  [2,2,1]   [0,1]  \n",
       "1    [2,2]   [0,0]  \n",
       "2      [1]     [2]  \n",
       "3      [2]   [2,2]  \n",
       "4      [1]     [0]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Human_Annotation_Data.xlsx')\n",
    "\n",
    "#df.dropna(inplace=True)\n",
    "\n",
    "for feature in ['sentiments', 'HSent1', 'HSent2']:\n",
    "    df = prepros(df, feature)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Relevancy !!\n",
      "RelClaim1  --  1.8780487804878048\n",
      "RelWhat1  --  1.75\n",
      "RelWhy1  --  1.6666666666666667\n",
      "RelClaim2  --  1.6097560975609757\n",
      "RelWhat2  --  1.6666666666666667\n",
      "RelWhy2  --  1.3333333333333333\n",
      "\n",
      "\n",
      "iAA :P\n",
      "RelClaim1 RelClaim2 0.36379310344827587\n",
      "RelWhat1 RelWhat2 0.7948717948717949\n",
      "RelWhy1 RelWhy2 0.475\n"
     ]
    }
   ],
   "source": [
    "scores = {}#{'RelClaim': [], 'RelWhat': [], 'RelWhy': []}\n",
    "\n",
    "tmp = df.dropna().reset_index(drop=True)\n",
    "sc = ['RelClaim1', 'RelWhat1', 'RelWhy1', 'RelClaim2', 'RelWhat2', 'RelWhy2']\n",
    "for feature in sc:\n",
    "    tmp[feature] = tmp[feature].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "for i in sc:\n",
    "    for j in tmp[i]:\n",
    "        try:\n",
    "            scores[i] += j\n",
    "        except:\n",
    "            scores[i] = j\n",
    "\n",
    "print(\"Score for Relevancy !!\")\n",
    "for i in scores:\n",
    "    print(i, \" -- \", mean(scores[i]))\n",
    "\n",
    "print(\"\\n\\niAA :P\")\n",
    "for i in range(3):\n",
    "    print(sc[i], sc[i+3], cohen_kappa_score(scores[sc[i]], scores[sc[i+3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty :(\n",
      "empty :(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9333333333333333, 0.875)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score for entity's recall !!\n",
    "def recall_calc(Lhuman, Lmodel):\n",
    "    if(len(Lhuman)==0):\n",
    "        print(\"empty :(\")\n",
    "        return 1\n",
    "    \n",
    "    return len(Lhuman.intersection(Lmodel)) / len(Lhuman)\n",
    "\n",
    "recall1 = []\n",
    "recall2 = []\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "    S_llm = row.sentiments.keys()\n",
    "    S1 = set(row.HSent1.keys())\n",
    "    S2 = set(row.HSent2.keys())\n",
    "\n",
    "    recall1.append(recall_calc(S1, S_llm))\n",
    "    recall2.append(recall_calc(S2, S_llm))\n",
    "\n",
    "mean(recall1), mean(recall2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No issue\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative    0.70588   1.00000   0.82759        12\n",
      "     neutral    1.00000   0.60000   0.75000        10\n",
      "    positive    1.00000   0.75000   0.85714         4\n",
      "\n",
      "    accuracy                        0.80769        26\n",
      "   macro avg    0.90196   0.78333   0.81158        26\n",
      "weighted avg    0.86425   0.80769   0.80229        26\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative    0.70588   1.00000   0.82759        12\n",
      "     neutral    1.00000   0.60000   0.75000        10\n",
      "    positive    1.00000   0.75000   0.85714         4\n",
      "\n",
      "    accuracy                        0.80769        26\n",
      "   macro avg    0.90196   0.78333   0.81158        26\n",
      "weighted avg    0.86425   0.80769   0.80229        26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "g1 = []\n",
    "g2 = []\n",
    "llm = []\n",
    "for i in range(len(df)):\n",
    "    row = df.iloc[i]\n",
    "    for j in row.sentiments:\n",
    "        try:\n",
    "            g1.append(row.HSent1[j])\n",
    "            g2.append(row.HSent2[j])\n",
    "            llm.append(row.sentiments[j])\n",
    "        except:\n",
    "            if(len(g1)==len(g2) and len(g2)==len(llm)):\n",
    "                print(\"No issue\")\n",
    "            elif(len(g1)>len(g2)):\n",
    "                g1 = g1[:-1]\n",
    "            elif(len(g2)>len(llm)):\n",
    "                g1 = g1[:-1]\n",
    "                g2 = g2[:-1]\n",
    "\n",
    "print(classification_report(g1, llm, digits=5))\n",
    "print(classification_report(g2, llm, digits=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
